{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc539eff",
   "metadata": {},
   "source": [
    "# PDF Investor Summarizer \n",
    "\n",
    "This notebook demonstrates how to use the [pdf-investor-summarizer](https://github.com/ashishki/pdf-investor-summarizer) project to automatically extract investment-relevant insights from company PDF reports using an LLM (OpenAI GPT).\n",
    "\n",
    "**Features:**\n",
    "- Loads and parses PDF files (local or public URL)\n",
    "- Cleans and splits text for efficient LLM extraction\n",
    "- Asks the LLM for a structured summary (growth, changes, triggers, material factors)\n",
    "- Supports cost/token accounting and error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c7d63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  1. Install dependencies (for Colab)\n",
    "\n",
    "# Option 1: pip install from GitHub\n",
    "!pip install git+https://github.com/ashishki/pdf-investor-summarizer.git\n",
    "\n",
    "# Option 2: clone + pip install local \n",
    "!git clone https://github.com/ashishki/pdf-investor-summarizer.git\n",
    "%cd pdf-investor-summarizer\n",
    "!pip install .\n",
    "\n",
    "# (Optional) For OCR support in Colab:\n",
    "# !apt-get install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49619e3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  2. Import project modules\n",
    "\n",
    "# All necessary modules are now available from the installed package.\n",
    "import os\n",
    "import asyncio\n",
    "from src.pdf_investor_summarizer.report_analyzer import ReportAnalyzer\n",
    "\n",
    "# (If you want to edit or debug, you can clone the repo instead of pip install)\n",
    "# !git clone https://github.com/ashishki/pdf-investor-summarizer.git\n",
    "# %cd pdf-investor-summarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780120f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  3. Configure your API key and input PDF\n",
    "\n",
    "# Set your OpenAI API key (required for the LLM)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # <-- Replace with your key!\n",
    "\n",
    "# Path to the default demo PDF (bundled with the repo)\n",
    "PDF_SOURCE = \"assets/company_report.pdf\"\n",
    "print(f\"Default demo PDF: {PDF_SOURCE}\")\n",
    "\n",
    "# Optional: If user uploads another file, use it instead\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "if uploaded:\n",
    "    PDF_SOURCE = list(uploaded.keys())[0]\n",
    "    print(f\"Using uploaded PDF: {PDF_SOURCE}\")\n",
    "else:\n",
    "    print(\"No upload detected, using demo PDF.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925e075",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  4. Run the summarization pipeline\n",
    "\n",
    "# Instantiate the main analyzer. Chunk size and overlap can be tuned for your document size.\n",
    "analyzer = ReportAnalyzer(chunk_size=2000, overlap=200)\n",
    "\n",
    "# Run the analysis pipeline asynchronously (required for LLM API calls)\n",
    "result = asyncio.run(analyzer.analyze_async(PDF_SOURCE))\n",
    "\n",
    "# Show the structured summary output\n",
    "import json\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76222cc3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  5. (Optional) How much did this cost?\n",
    "\n",
    "# Token/cost stats are already logged to console by the pipeline.\n",
    "# If you want to analyze further, you can add custom print statements or save stats from result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb17599",
   "metadata": {},
   "source": [
    "## Notes & Tips\n",
    "\n",
    "- The pipeline supports both local files and public PDF URLs (except direct links from Google Drive/Dropbox/OneDrive — see README).\n",
    "- If you get a PDF parsing error, make sure your input is a real PDF file, not a web page.\n",
    "- For large files, costs and runtime may increase — try with a short report first.\n",
    "- Adjust chunk size and overlap for your use-case: smaller values = cheaper but possibly less context.\n",
    "- All token/cost stats and errors are printed in the output cells for transparency and easy debugging.\n",
    "- For Google Drive, download your PDF to local disk and then upload via Colab.\n",
    "- Poetry is used for development, but for Colab you only need pip install.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
