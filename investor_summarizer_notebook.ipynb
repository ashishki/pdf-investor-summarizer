{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RaW1HwfZr9P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Investor Summarizer\n",
        "\n",
        "This notebook demonstrates how to use the [pdf-investor-summarizer](https://github.com/ashishki/pdf-investor-summarizer) project to automatically extract investment-relevant insights from company PDF reports using an LLM (OpenAI GPT).\n",
        "\n",
        "**Features:**\n",
        "- Loads and parses PDF files (local or public URL)\n",
        "- Cleans and splits text for efficient LLM extraction\n",
        "- Asks the LLM for a structured summary (growth, changes, triggers, material factors)\n",
        "- Supports cost/token accounting and error handling"
      ],
      "metadata": {
        "id": "WuRm-qEyZ0JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Install project dependencies (always run first) ---\n",
        "\n",
        "!git clone https://github.com/ashishki/pdf-investor-summarizer.git\n",
        "%cd pdf-investor-summarizer\n",
        "!pip install .\n",
        "\n",
        "# (Optional) For OCR support in Colab:\n",
        "# !apt-get install tesseract-ocr"
      ],
      "metadata": {
        "id": "BWigF18eZ27J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Import modules ---\n",
        "import os\n",
        "import asyncio\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from src.pdf_investor_summarizer.report_analyzer import ReportAnalyzer\n",
        "\n"
      ],
      "metadata": {
        "id": "_UHny2-mo6I7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key (required for the LLM)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # <-- Replace with your key!"
      ],
      "metadata": {
        "id": "zXRlKbkSwmJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the default demo PDF (bundled with the repo)\n",
        "PDF_SOURCE = \"tests/assets/company_report.pdf\"\n",
        "print(f\"Default demo PDF: {PDF_SOURCE}\")\n",
        "\n",
        "# Optional: If user uploads another file, use it instead\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    PDF_SOURCE = list(uploaded.keys())[0]\n",
        "    print(f\"Using uploaded PDF: {PDF_SOURCE}\")\n",
        "else:\n",
        "    print(\"No upload detected, using demo PDF.\")\n"
      ],
      "metadata": {
        "id": "gzBvgBARsnTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. (Optional) Validate that PDF_SOURCE is a real PDF file ---\n",
        "with open(PDF_SOURCE, \"rb\") as f:\n",
        "    signature = f.read(4)\n",
        "if not signature.startswith(b\"%PDF\"):\n",
        "    raise ValueError(\"Selected file is not a valid PDF!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "inPXEjfGaHRs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Run the summarization pipeline ---\n",
        "analyzer = ReportAnalyzer(chunk_size=2000, overlap=200)\n",
        "result = await analyzer.analyze_async(PDF_SOURCE)"
      ],
      "metadata": {
        "id": "2QqmzXK9nXuM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Show the structured summary output ---\n",
        "import json\n",
        "print(json.dumps(result, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "id": "g_xT-afhojux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  (Optional) How much did this cost?\n",
        "\n",
        "# Token/cost stats are already logged to console by the pipeline.\n",
        "# If you want to analyze further, you can add custom print statements or save stats from result."
      ],
      "metadata": {
        "id": "a7fFaBu6aNag"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes & Tips\n",
        "\n",
        "- The pipeline supports both local files and public PDF URLs (except direct links from Google Drive/Dropbox/OneDrive — see README).\n",
        "- If you get a PDF parsing error, make sure your input is a real PDF file, not a web page.\n",
        "- For large files, costs and runtime may increase — try with a short report first.\n",
        "- Adjust chunk size and overlap for your use-case: smaller values = cheaper but possibly less context.\n",
        "- All token/cost stats and errors are printed in the output cells for transparency and easy debugging.\n",
        "- For Google Drive, download your PDF to local disk and then upload via Colab.\n",
        "- Poetry is used for development, but for Colab you only need pip install.\n"
      ],
      "metadata": {
        "id": "JGuXtpAFaWqT"
      }
    }
  ]
}